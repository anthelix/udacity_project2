{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My working directory :\n",
      "/home/anthelix/Documents/projetGit/20200123_project2_cassandra\n",
      "My path :\n",
      "/home/anthelix/Documents/projetGit/20200123_project2_cassandra/event_data\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print('My working directory :')\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "print('My path :')\n",
    "print(filepath)\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print(len(full_data_rows_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **event_datafile.csv** contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "\n",
    "<img src=\"image/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspacem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fe22893fc18>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"\"\"\n",
    "CREATE KEYSPACE IF NOT EXISTS uda\n",
    "WITH REPLICATION =\n",
    "{'class' : 'SimpleStrategy', 'replication_factor' : 1}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set KEYSPACE to the keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('uda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create queries to ask the following three questions of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "key: minimum set of attributes that uniquely identify an entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partition key is responsible for distributing data among nodes. A partition key is the same as the primary key when the primary key consists of a single column.  \n",
    "Partition keys belong to a node. Cassandra is organized into a cluster of nodes, with each node having an equal part of the partition key hashes.  \n",
    "The Partition Key is useful for locating the data in the node in a cluster  \n",
    "Selecting a proper partition key helps avoid overloading of any one node in a Cassandra cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " while the primary key represents a unique gym record/row, all gyms within a country reside on the same partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partion key are fields used to create row key in order to \n",
    "* determine how the data is partitioned\n",
    "* determine what is phisically stored in a single row\n",
    "* referred as row key or partition key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering keys are responsible for sorting data within a partition. Each primary key column after the partition key is considered a clustering key  \n",
    "The clustering key specifies the sorted order of the data within the selected partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustering ket are column family fields to cluster a row key in order to  \n",
    "* create logical sets inside a single row\n",
    "* allow more flexible search schemes such as range range\n",
    "* referred as column key or cluster key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chebotko Mapping rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based  on  the  above  data  modeling  principles,  we  definefive mapping rules that guide a query-driven transition from aconceptual data model to a logical data model.  \n",
    "* MR1 (Entities and Relationships).**Entity  and  relationshiptypes map to tables**, while entities and relationships map to ta-ble rows. Attribute types that describe entities and relationships at the conceptual level must be preserved as table columns atthe logical level. Violation of this rule may lead to data loss\n",
    "* MR2 (Equality Search Attributes).**Equality   search   at-tributes**, which are used in a query predicate, map to the prefixcolumns of a table primary key. Such columns must include allpartition key columns and, optionally, one or more clusteringkey  columns.  Violation  of  this  rule  may  result  in  inability  tosupport query requirements.\n",
    "* MR3 (Inequality Search Attributes).**An inequality  search attribute, which is used in a query predicate, maps to a tableclustering key column**. In the primary key definition, a column that participates in inequality search must follow columns that participate in equality search. Violation of this rule may resultin inability to support query requirements.\n",
    "* MR4 (Ordering Attributes).**Ordering attributes, which arespecified  in  a  query,  map  to  clustering  key  columns**  withascending or descending clustering order as prescribed by thequery. Violation of this rule may result in inability to supportquery requirements.\n",
    "* MR5 (Key Attributes).**Key attribute types map to primarykey  columns**.  A  table  that  stores  entities  or  relationships  asrows  must  include  key  attributes  that  uniquely  identify  theseentities  or  relationships  as  part  of  the  table  primary  key  touniquely  identify  table  rows.  Violation  of  this  rule  may  leadto data loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   * MR1 (Entités et relations) : les types d'entités et de relations correspondent aux tables, tandis que les entités et les relations correspondent aux lignes des tables. Les types d'attributs qui décrivent les entités et les relations au niveau conceptuel doivent être conservés sous forme de colonnes de table au niveau logique. Le non-respect de cette règle peut entraîner la perte de données\n",
    "   * MR2 (Equality Search Attributes) : les attributs de recherche sur l'égalité, utilisés dans un prédicat de requête, correspondent aux préfixes de la clé primaire d'une table. Ces colonnes doivent comprendre toutes les colonnes de clés de partition et, éventuellement, une ou plusieurs colonnes de clés de regroupement. Le non-respect de cette règle peut entraîner l'impossibilité de prendre en charge les exigences de la requête.\n",
    "   * MR3 (Inequality Search Attributes) : un attribut de recherche d'inégalité, utilisé dans un prédicat de requête, correspond à une colonne de clé de regroupement de tables. Dans la définition de la clé primaire, une colonne qui participe à la recherche d'inégalités doit suivre les colonnes qui participent à la recherche d'égalité. Le non-respect de cette règle peut entraîner l'impossibilité de répondre aux exigences de la requête.\n",
    "   * MR4 (Ordering Attributes) : les attributs d'ordre, qui sont spécifiés dans une requête, correspondent à des colonnes clés de regroupement avec un ordre de regroupement ascendant ou descendant tel que prescrit par la requête. Le non-respect de cette règle peut entraîner l'impossibilité de répondre aux exigences de la requête.\n",
    "  * MR5 (Key Attributes) : les types d'attributs clés correspondent à des colonnes de clés primaires. Une table qui stocke des entités ou des relations sous forme de rangées doit inclure des attributs clés qui identifient de manière unique ces entités ou relations dans le cadre de la clé primaire de la table qui identifie les rangées de la table. Le non-respect de cette règle peut entraîner la perte de données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ERD project2](./image/erd_project2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mapping Rules](./image/mappingRules.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. les types d'entités et de relations correspondent aux tableaux\n",
    "2. les attributs clés correspondent aux principales colonnes clés\n",
    "3. Les attributs de recherche de l'égalité permettent de partitionner les colonnes clés\n",
    "4. Les attributs de recherche sur les inégalités permettent de regrouper les colonnes\n",
    "5. Ordonner les attributs de la carte pour regrouper les colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. name each table, identify the primary entity type for which we are quering. if querying by attributs of other related entities, we append those separated with `_by_`\n",
    "2. identify the primary key\n",
    "    * en ajoutant des colonnes de cles de partition basees sur les attributs de requete\n",
    "    * en regroupant les colonnes pour garantir l'unicite et l'ordre de tri souhaite\n",
    "3. on complete la table en ajoutant tout attribut suplementaire identifie par la requete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. mapping entity and relationship in a box with his title and by order of the query\n",
    "2. mapping search equality attributes (as K)\n",
    "3. mapping serch inequality attributes (as C)\n",
    "4. mapping ordering attributes (asc or desc)\n",
    "5. mapping key attributes (desired attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "![quer1](./image/quer1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table song_by_session  \n",
    "As we search in `sessionId` and `itemInSession`,  they become the partition key. `artist`, `song` and `length` are what we looking for.  \n",
    "![Table](./image/query1_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table for the first query\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_by_session\"\n",
    "query = query + \"(sessionId INT, itemInSession INT, artist VARCHAR, song VARCHAR, length DECIMAL, PRIMARY KEY(sessionId, itemInSession))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_by_session(sessionId, itemInSession, artist, song, length)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless --- Music Matters (Mark Knight Dub) --- 495.3073\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM song_by_session WHERE sessionId = 338 AND itemInSession = 4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row.artist,\"---\", row.song,\"---\" ,row.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "![query2](./image/query2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table song_by_user  \n",
    "As we search in `userId` and `sessionId`, they becomes the partition key and `itemInSession` the clustering key for sorted the `song`. `artist`, `song`, `fisrtName` and `lastName` are what we looking for. \n",
    "![Table](./image/query2_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table for the second query\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_by_user\"\n",
    "query = query +\"(userId INT, sessionId INT, itemInSession INT, artist VARCHAR, song VARCHAR, firstName VARCHAR, lastName VARCHAR, PRIMARY KEY((userId, sessionId), itemInSession))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoHostAvailable",
     "evalue": "('Unable to complete the operation against any hosts', {<Host: 127.0.0.1:9042 datacenter1>: ConnectionException('Pool is shutdown',)})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoHostAvailable\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-d9483477195c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cassand3/lib/python3.6/site-packages/cassandra/cluster.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.Session.execute\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cassand3/lib/python3.6/site-packages/cassandra/cluster.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNoHostAvailable\u001b[0m: ('Unable to complete the operation against any hosts', {<Host: 127.0.0.1:9042 datacenter1>: ConnectionException('Pool is shutdown',)})"
     ]
    }
   ],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## TO-DO: Assign the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO song_by_user(userId, sessionId, itemInSession, artist, song, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM song_by_user WHERE userId = 10 AND sessionId = 182\"\n",
    "try:\n",
    "    rows2 = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 182, 0, 'Down To The Bone')\n",
      "(10, 182, 1, 'Three Drives')\n",
      "(10, 182, 2, 'Sebastien Tellier')\n",
      "(10, 182, 3, 'Lonnie Gordon')\n"
     ]
    }
   ],
   "source": [
    "# to check the order\n",
    "for row in rows2:\n",
    "    print(row[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone --- Keep On Keepin' On --- Sylvie Cruz\n",
      "Three Drives --- Greece 2000 --- Sylvie Cruz\n",
      "Sebastien Tellier --- Kilometer --- Sylvie Cruz\n",
      "Lonnie Gordon --- Catch You Baby (Steve Pitron & Max Sanna Radio Edit) --- Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "# the answer to the query2\n",
    "for row in rows2:\n",
    "    print(row.artist,\"---\" ,row.song, \"---\", row.firstname, row.lastname)\n",
    "# name of artist, song (sorted by itemInSession) and user (first and last name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "![query3](./image/query3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table user_by_song  \n",
    "As we search in `song` it's become the primary key and `userId` the clustering to find `firstName` and `lastName`. \n",
    "![Table](./image/query3_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table for the third query\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_by_song\"\n",
    "query = query + \"(song VARCHAR, userId INT, firstName VARCHAR, lastNAME VARCHAR, PRIMARY KEY(song, userId))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## TO-DO: Assign the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO user_by_song(song, userId, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM user_by_song WHERE song='All Hands Against His Own'\"\n",
    "try:\n",
    "    rows2 = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows2:\n",
    "    print(\"{} {}\".format(row[-2], row[-1]))\n",
    "# Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"DROP TABLE song_by_session\"\n",
    "query2 = \"DROP TABLE song_by_user\"\n",
    "query3 = \"DROP TABLE user_by_song\"\n",
    "\n",
    "try:\n",
    "    rows1 = session.execute(query1)\n",
    "    rows2 = session.execute(query2)\n",
    "    rows3 = session.execute(query3)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
